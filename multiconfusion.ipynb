{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multivariate-confusion  matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data of confusion matrix row wise.... Assuming there are 5 classes\n",
    "con=np.array([[8,4,3,2,1],[4,8,3,2,1],[4,3,8,2,1],[4,3,2,8,1],[4,3,2,1,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label precision sensitivity specificity f1-score\n",
      "  0   0.3333     0.4444      0.5556      0.3810\n",
      "  1   0.3810     0.4444      0.5556      0.4103\n",
      "  2   0.4444     0.4444      0.5556      0.4444\n",
      "  3   0.5333     0.4444      0.5556      0.4848\n",
      "  4   0.6667     0.4444      0.5556      0.5333\n"
     ]
    }
   ],
   "source": [
    "class confusion():\n",
    "    def __init__(self):\n",
    "        self\n",
    "    ########################################################################\n",
    "    #calculating the precision:    \n",
    "    def precision(self,data,i): #precision=right predictions/(right predictions+wrong predictions) for each class\n",
    "        column=data[:,i] #creating a list which contains all the elements of 'i' column\n",
    "        return data[i,i]/column.sum()\n",
    "    #########################################################################\n",
    "    #calculating the sensitivity:\n",
    "    def sensitivity(self,data,i):#sensitivity=right class/all the predicitions for that class\n",
    "        row=data[i,:]#creating a list which contains all the elements of 'i' row\n",
    "        return data[i,i]/row.sum()\n",
    "    #########################################################################\n",
    "    #calculating the specificity:\n",
    "    def specificity(self,data,i):#specificity=wrong predictions of a class/all the predicitions for that class\n",
    "        row=data[i,:]\n",
    "        s_row=list(row)\n",
    "        data=s_row[i]\n",
    "        s_row.remove(data)#removing the data at [i,i] location (the  \n",
    "        s_row=np.array(s_row)\n",
    "        return s_row.sum()/row.sum()\n",
    "    ##########################################################################\n",
    "    #calculating the accuracy:\n",
    "    def accuracy(self,data):\n",
    "        dig_sum=data.trace()#calculating the sum of all true-positives\n",
    "        return dig_sum/data.sum()\n",
    "    ##########################################################################\n",
    "    #calculating f1-score:\n",
    "    def f1_score(self,data,i):\n",
    "        prec=self.precision(data,i)\n",
    "        sens=self.sensitivity(data,i)\n",
    "        return (2*prec*sens)/(prec+sens)\n",
    "    #########################################################################\n",
    "    #calculating macro-averages:\n",
    "    def macro_sense(self,data): #for sensitivity\n",
    "        row,col=data.shape\n",
    "        sumr=0\n",
    "        for i in range(row):\n",
    "            sumr+=self.sensitivity(data,i)#total of all recall or sensitivity\n",
    "        return sumr/row\n",
    "    def macro_spec(self,data): #for specificity\n",
    "        row,col=data.shape\n",
    "        sums=0\n",
    "        for i in range(row):\n",
    "            sums+=self.specificity(data,i)#total of all specificity\n",
    "        return sums/row\n",
    "    def macro_prec(self,data): #for precision\n",
    "        row,col=data.shape\n",
    "        sump=0\n",
    "        for i in range(row):\n",
    "            sump+=self.precision(data,i)#total of all precision\n",
    "        return sump/row\n",
    "    #############################################################################\n",
    "    #############################################################################\n",
    "                \n",
    "clf=confusion()\n",
    "print('label precision sensitivity specificity f1-score')\n",
    "for j in range(5):\n",
    "    print(f'{j:3d}{clf.precision(con,j):9.4f}{clf.sensitivity(con,j):11.4f}{clf.specificity(con,j):12.4f}{clf.f1_score(con,j):12.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 0.4444444444444444\n",
      "avg.precision= 0.4717460317460317\n",
      "avg.sensitivity= 0.4444444444444445\n",
      "avg.specificity= 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "print('accuracy=',clf.accuracy(con))\n",
    "print('avg.precision=',clf.macro_prec(con))\n",
    "print('avg.sensitivity=',clf.macro_sense(con))\n",
    "print('avg.specificity=',clf.macro_spec(con))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
